{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3edf2f9",
   "metadata": {},
   "source": [
    "# Explaining Model Behaviour and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b2c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "import os\n",
    "os.chdir(\"/home/ronja/GDELT_GKG\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c0a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "dataset_extension = \"_mbfc_allbias_extrafeatures\"\n",
    "\n",
    "train = pd.read_csv(\"data/train{}.csv\".format(dataset_extension))\n",
    "train.set_index(\"outlet\", inplace=True)\n",
    "\n",
    "val = pd.read_csv(\"data/val{}.csv\".format(dataset_extension))\n",
    "val.set_index(\"outlet\", inplace=True)\n",
    "\n",
    "test = pd.read_csv(\"data/test{}.csv\".format(dataset_extension))\n",
    "test.set_index(\"outlet\", inplace=True)\n",
    "\n",
    "# split each dataset into X and y's\n",
    "X_train = train.drop(\"lean\", axis=1)\n",
    "y_train = train[\"lean\"]\n",
    "\n",
    "X_val = val.drop(\"lean\", axis=1)\n",
    "y_val = val[\"lean\"]\n",
    "\n",
    "X_test = test.drop(\"lean\", axis=1)\n",
    "y_test = test[\"lean\"]\n",
    "\n",
    "# combine all sets so we can visualise the explanation for ANY outlet\n",
    "X = pd.concat([X_train,X_val,X_test])\n",
    "y = pd.concat([y_train,y_val,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9677f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a model\n",
    "model = joblib.load(\"results/best_SVC_model.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a079b6",
   "metadata": {},
   "source": [
    "## Part 1. SHAP\n",
    "\n",
    "Decision plots: https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/decision_plot.html?highlight=force#Show-a-large-number-of-feature-effects-clearly\n",
    "\n",
    "Heatmap plots: https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/heatmap.html\n",
    "\n",
    "Beeswax plots (violin): https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/beeswarm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize JavaScript for visualizing the outputs\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make explainer object before to make sure this runs faster - on training set though!\n",
    "explainer = shap.KernelExplainer(model.predict, X_train)\n",
    "\n",
    "# make function for plotting a single outlet's decision plot\n",
    "def decision_plot_for_outlet(outlet_name, model, explainer,title):\n",
    "    classes_dict = {0:\"Left\", 1:\"Left lean\",2:\"Least biased\", 3:\"Right lean\",4:\"Right\"}\n",
    "    print(\"The outlet is: \", outlet_name)\n",
    "    print(\"Political leaning is: \", classes_dict[y.loc[outlet_name]])\n",
    "    # get predicted leaning\n",
    "    y_pred = model.predict(X.loc[outlet_name,:].values.reshape(1, -1))[0]\n",
    "    print(\"Political leaning predicted as: \", classes_dict[y_pred])\n",
    "    # explain the outlet in question\n",
    "    shap_values = explainer.shap_values(X.loc[outlet_name,:])\n",
    "    # make decision plot of top 20 most influential features\n",
    "    shap.decision_plot(explainer.expected_value, \n",
    "                       shap_values, \n",
    "                       X.loc[outlet_name,:],\n",
    "                       show=0\n",
    "                      )\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef629c2",
   "metadata": {},
   "source": [
    "### Get decision plot for a single outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples to examine\n",
    "\"cnn.com\" # test\n",
    "\"foxnews.com\" # test \n",
    "\"breitbart.com\" # test\n",
    "\"theguardian.com\" # test\n",
    "\"dailymail.co.uk\" # test\n",
    "\n",
    "decision_plot_for_outlet(\"cnn.com\",model=model,explainer=explainer, title=\"Decision Plot for CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_plot_for_outlet(\"breitbart.com\",model=model,explainer=explainer, title=\"Decision Plot for Breitbart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297550ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_plot_for_outlet(\"theguardian.com\",model=model,explainer=explainer, title=\"Decision Plot for the Guardian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_plot_for_outlet(\"dailymail.co.uk\",model=model,explainer=explainer, title=\"Decision Plot for Daily Mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafedce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision_plot_for_outlet(\"foxnews.com\",model=model,explainer=explainer, title=\"Decision Plot for Fox News\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8064c8ab",
   "metadata": {},
   "source": [
    "### Get decision plot for a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28db1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indexes = {\n",
    "    \"left\": np.where(y == 0)[0],\n",
    "    \"left lean\": np.where(y == 1)[0],\n",
    "    \"least biased\": np.where(y == 2)[0],\n",
    "    \"right lean\": np.where(y == 3)[0],\n",
    "    \"right\": np.where(y == 4)[0],\n",
    "}\n",
    "\n",
    "selection = class_indexes[\"left lean\"][:10] # let's just get the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_multiple_outlets(selection, X, explainer,title=\"\"):\n",
    "    shap_values = explainer.shap_values(X.iloc[selection,:])\n",
    "    # make decision plot of top 20 most influential features\n",
    "    y_pred = model.predict(X.iloc[selection,:])\n",
    "    misclassified = y_pred != y[selection]\n",
    "    shap.decision_plot(explainer.expected_value, \n",
    "                       shap_values, \n",
    "                       X.iloc[selection,:], \n",
    "                       highlight=misclassified,\n",
    "                       show=0\n",
    "                      )\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = class_indexes[\"left lean\"][:10]\n",
    "misclassified = explain_multiple_outlets(selection=selection, X=X, \n",
    "                                         explainer=explainer,\n",
    "                                         title=\"Feature Importance of Left Lean Outlets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12803d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = class_indexes[\"least biased\"][:10]\n",
    "misclassified = explain_multiple_outlets(selection=selection, X=X, \n",
    "                                         explainer=explainer,\n",
    "                                         title=\"Feature Importance of Least Biased Outlets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = class_indexes[\"right lean\"][:10]\n",
    "misclassified = explain_multiple_outlets(selection=selection, X=X, \n",
    "                                         explainer=explainer,\n",
    "                                         title=\"Feature Importance of Right Lean Outlets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = class_indexes[\"right\"][:10]\n",
    "misclassified = explain_multiple_outlets(selection=selection, X=X, \n",
    "                                         explainer=explainer,\n",
    "                                         title=\"Feature Importance of Right Outlets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa120ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified[misclassified == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the one misclassified outlet specifically\n",
    "misclassified_outlet = \"torontosun.com\" #misclassified[misclassified == True].index[0]\n",
    "decision_plot_for_outlet(misclassified_outlet,model=model,explainer=explainer,title=\"Misclassidied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f24a4",
   "metadata": {},
   "source": [
    "### Make plot for all classes\n",
    "https://github.com/Rakeshsuku/Medium-Blog/blob/master/Kernel_SHAP.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96996da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class_indexes = {\n",
    "    \"left\": np.where(y == 0)[0],\n",
    "    \"left lean\": np.where(y == 1)[0],\n",
    "    \"least biased\": np.where(y == 2)[0],\n",
    "    \"right lean\": np.where(y == 3)[0],\n",
    "    \"right\": np.where(y == 4)[0],\n",
    "}\n",
    "\n",
    "# visualize decision plots per class\n",
    "small_selection_of_all_classes = np.concatenate([class_indexes[\"left\"][:5],class_indexes[\"left lean\"][:5],\n",
    "                                                 class_indexes[\"least biased\"][:5],class_indexes[\"right lean\"][:5],\n",
    "                                                 class_indexes[\"right\"][:5]])\n",
    "\n",
    "class_explainer = shap.KernelExplainer(model.predict_proba, data=X_train)\n",
    "# get shap values for the subset\n",
    "shap_values = class_explainer.shap_values(X.iloc[small_selection_of_all_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee817c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shap plot for all classes\n",
    "shap.summary_plot(shap_values = shap_values,\n",
    "                  features = X.iloc[small_selection_of_all_classes],\n",
    "                  class_names = [\"Left\",\"L-lean\",\"Center\",\"R-lean\",\"Right\"],\n",
    "                  max_display = 10,\n",
    "                  plot_size = 0.3,\n",
    "                  show=0\n",
    "                  )\n",
    "plt.title(\"Feature Impacts per Political Bias Class\")\n",
    "plt.xlim(0,0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shap plot for all classes\n",
    "shap.summary_plot(shap_values = shap_values,\n",
    "                  features = X.iloc[small_selection_of_all_classes],\n",
    "                  class_names = [\"Left\",\"L-lean\",\"Center\",\"R-lean\",\"Right\"],\n",
    "                  max_display = 10,\n",
    "                  plot_size = 0.3,\n",
    "                  plot_type = \"violin\",\n",
    "                  show=0\n",
    "                  )\n",
    "plt.title(\"Feature Impacts per Political Bias Class\")\n",
    "plt.xlim(0,0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fda3dd",
   "metadata": {},
   "source": [
    "## Explainability with Feature Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09fb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#calculate permutation importance for test data \n",
    "result_test = permutation_importance(\n",
    "    clf, X_test, y_test, n_repeats=20, random_state=42, n_jobs=2\n",
    ")\n",
    "# get sorted importances for visualising it in descending order\n",
    "sorted_importances_idx_test = result_test.importances_mean.argsort()\n",
    "\n",
    "importances_test = pd.DataFrame(\n",
    "    result_test.importances[sorted_importances_idx_test].T,\n",
    "    columns=X_train.columns[sorted_importances_idx_test],\n",
    ")\n",
    "\n",
    "# plot it from DF\n",
    "plt.figure()\n",
    "importances_test.iloc[:,:10].plot.box(vert=False, whis=10)\n",
    "plt.title(\"Permutation Importances (test set)\")\n",
    "plt.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "plt.xlabel(\"Decrease in accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84164129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
